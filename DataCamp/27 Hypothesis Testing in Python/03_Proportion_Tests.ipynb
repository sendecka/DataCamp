{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Proportion Tests\n",
    "\n",
    "Now it’s time to test for differences in proportions between two groups using proportion tests. Through hands-on exercises, you’ll extend your proportion tests to more than two groups with chi-square independence tests, and return to the one sample case with chi-square goodness of fit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for single proportions\n",
    "\n",
    "In Chapter 1, you calculated a p-value for a test hypothesizing that the proportion of late shipments was greater than 6%. In that chapter, you used a bootstrap distribution to estimate the standard error of the statistic. An alternative is to use an equation for the standard error based on the sample proportion, hypothesized proportion, and sample size.\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "You'll revisit the p-value using this simpler calculation.\n",
    "\n",
    "late_shipments is available. pandas and numpy are available under their usual aliases, and norm is loaded from scipy.stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Hypothesize that the proportion of late shipments is 6%.\n",
    "- Calculate the sample proportion of shipments where late equals \"Yes\".\n",
    "- Calculate the number of observations in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Print p_hat and n\n",
    "print(p_hat, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the numerator and denominator of the z-score.\n",
    "- Calculate the z-score as the ratio of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Print the result\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform the z-score into a p-value, remembering that this is a \"greater than\" alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print the p-value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of two proportions\n",
    "\n",
    "You may wonder if the amount paid for freight affects whether or not the shipment was late. Recall that in the late_shipments dataset, whether or not the shipment was late is stored in the late column. Freight costs are stored in the freight_cost_group column, and the categories are \"expensive\" and \"reasonable\".\n",
    "\n",
    "The hypotheses to test, with \"late\" corresponding to the proportion of late shipments for that group, are\n",
    "\n",
    "p_hats contains the estimates of population proportions (sample proportions) for each freight_cost_group:\n",
    "\n",
    "freight_cost_group  late\n",
    "expensive           Yes     0.082569\n",
    "reasonable          Yes     0.035165\n",
    "Name: late, dtype: float64\n",
    "ns contains the sample sizes for these groups:\n",
    "\n",
    "freight_cost_group\n",
    "expensive     545\n",
    "reasonable    455\n",
    "Name: late, dtype: int64\n",
    "pandas and numpy have been imported under their usual aliases, and norm is available from scipy.stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Calculate the pooled sample proportion, \n",
    ", from p_hats and ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Print the result\n",
    "print(p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the standard error of the sample using this equation. Calculate p_hat multiplied by (1 - p_hat).\n",
    "Divide p_hat_times_not_p_hat by the number of \"reasonable\" rows and by the number of \"expensive\" rows, and sum those two values.\n",
    "Calculate std_error by taking the square root of p_hat_times_not_p_hat_over_ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Print the result\n",
    "print(std_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the z-score using the following equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Print z_score\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the p-value from the z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print p_value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proportions_ztest() for two samples\n",
    "\n",
    "That took a lot of effort to calculate the p-value, so while it is useful to see how the calculations work, it isn't practical to do in real-world analyses. For daily usage, it's better to use the statsmodels package.\n",
    "\n",
    "Recall the hypotheses.\n",
    "\n",
    "late_shipments is available, containing the freight_cost_group column. numpy and pandas have been loaded under their standard aliases, and proportions_ztest has been loaded from statsmodels.stats.proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Get the counts of the late column grouped by freight_cost_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(late_by_freight_cost_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the number of \"Yes\"'s for the two freight_cost_group into a numpy array, specifying the 'expensive' count and then 'reasonable'.\n",
    "- Determine the overall number of rows in each freight_cost_group as a numpy array, specifying the 'expensive' count and then 'reasonable'.\n",
    "- Run a z-test using proportions_ztest(), specifying alternative as \"larger\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# Create an array of the \"Yes\" counts for each freight_cost_group\n",
    "success_counts = np.array([45, 16])\n",
    "\n",
    "# Create an array of the total number of rows in each freight_cost_group\n",
    "n = np.array([45 + 500, 16 + 439])\n",
    "\n",
    "# Run a z-test on the two proportions\n",
    "stat, p_value = proportions_ztest(count=success_counts, nobs=n,\n",
    "                                  alternative=\"larger\")\n",
    "\n",
    "# Print the results\n",
    "print(stat, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The chi-square distribution\n",
    "\n",
    "Chi-square hypothesis tests rely on the chi-square distribution. Like the t-distribution, it has degrees of freedom and non-centrality parameters.\n",
    "\n",
    "The plots show the PDF and CDF for a chi-square distribution (solid black line), and for comparison show a normal distribution with the same mean and variance (gray dotted line).\n",
    "\n",
    "Which statement about the chi-square distribution is true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( ) Like the normal distribution, the chi-square distribution is defined for x values from minus infinity to infinity.\n",
    "\n",
    "(x) As you increase the degrees of freedom or the non-centrality, the chi-square distribution PDF and CDF curves get closer to those of a normal distribution.\n",
    "\n",
    "( ) As you decrease the degrees of freedom or the non-centrality, the chi-square distribution PDF and CDF curves get closer to those of a normal distribution.\n",
    "\n",
    "( ) The chi-square distribution PDF is symmetric about its peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a chi-square test\n",
    "\n",
    "The chi-square independence test compares proportions of successes of one categorical variable across the categories of another categorical variable.\n",
    "\n",
    "Trade deals often use a form of business shorthand in order to specify the exact details of their contract. These are International Chamber of Commerce (ICC) international commercial terms, or incoterms for short.\n",
    "\n",
    "The late_shipments dataset includes a vendor_inco_term that describes the incoterms that applied to a given shipment. The choices are:\n",
    "\n",
    "EXW: \"Ex works\". The buyer pays for transportation of the goods.\n",
    "CIP: \"Carriage and insurance paid to\". The seller pays for freight and insurance until the goods board a ship.\n",
    "DDP: \"Delivered duty paid\". The seller pays for transportation of the goods until they reach a destination port.\n",
    "FCA: \"Free carrier\". The seller pays for transportation of the goods.\n",
    "Perhaps the incoterms affect whether or not the freight costs are expensive. Test these hypotheses with a significance level of 0.01.\n",
    "\n",
    ": vendor_inco_term and freight_cost_group are independent.\n",
    "\n",
    ": vendor_inco_term and freight_cost_group are associated.\n",
    "\n",
    "late_shipments is available, and the following have been loaded: matplotlib.pyplot as plt, pandas as pd, and pingouin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Calculate the proportion of freight_cost_group in late_shipments grouped by vendor_inco_term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Print props\n",
    "print(props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unstack the .value_counts() result to be in wide format instead of long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Print wide_props\n",
    "print(wide_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a proportional stacked bar plot with bars filled based on freight_cost_group across the levels of vendor_inco_term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "wide_props.plot(kind=\"bar\", stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform a chi-square test of independence on freight_cost_group and vendor_inco_term in the late_shipments dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "wide_props.plot(kind=\"bar\", stacked=True)\n",
    "plt.show()\n",
    "\n",
    "# Determine if freight_cost_group and vendor_inco_term are independent\n",
    "expected, observed, stats = pingouin.chi2_independence(data=late_shipments, x=\"vendor_inco_term\", y=\"freight_cost_group\")\n",
    "\n",
    "# Print results\n",
    "print(stats[stats['test'] == 'pearson']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "What should you conclude from the hypothesis test?\n",
    "# Possible answers\n",
    "\n",
    "( ) Fail to reject the null hypothesis and conclude that vendor_inco_term and freight_cost_group are independent.\n",
    "\n",
    "( ) Reject the null hypothesis and conclude that vendor_inco_term and freight_cost_group are independent.\n",
    "\n",
    "( ) Fail to reject the null hypothesis and conclude that vendor_inco_term and freight_cost_group are associated.\n",
    "\n",
    "(x) Reject the null hypothesis and conclude that vendor_inco_term and freight_cost_group are associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing goodness of fit\n",
    "\n",
    "The chi-square goodness of fit test compares proportions of each level of a categorical variable to hypothesized values. Before running such a test, it can be helpful to visually compare the distribution in the sample to the hypothesized distribution.\n",
    "\n",
    "Recall the vendor incoterms in the late_shipments dataset. You hypothesize that the four values occur with these frequencies in the population of shipments.\n",
    "\n",
    "CIP: 0.05\n",
    "DDP: 0.1\n",
    "EXW: 0.75\n",
    "FCA: 0.1\n",
    "These frequencies are stored in the hypothesized DataFrame.\n",
    "\n",
    "The incoterm_counts DataFrame stores the .value_counts() of the vendor_inco_term column.\n",
    "\n",
    "late_shipments is available; pandas and matplotlib.pyplot are loaded with their standard aliases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Find the total number of rows in late_shipments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Print n_total\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a column named n to the hypothesized DataFrame that is the hypothesized prop column times n_total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Print the modified hypothesized DataFrame\n",
    "print(hypothesized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a bar graph of 'n' versus 'vendor_inco_term' for the incoterm_counts data, specifying a red color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
    "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add blue bars to the plot showing the same results from the hypothesized DataFrame, specifying an alpha of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
    "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
    "\n",
    "# Add a blue bar plot for the hypothesized counts\n",
    "plt.bar(hypothesized['vendor_inco_term'], hypothesized['n'], alpha=0.5, color=\"blue\", label=\"Hypothesized\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a goodness of fit test\n",
    "\n",
    "The bar plot of vendor_inco_term suggests that the distribution across the four categories was quite close to the hypothesized distribution. You'll need to perform a chi-square goodness of fit test to see whether the differences are statistically significant.\n",
    "\n",
    "Recall the hypotheses for this type of test:\n",
    "\n",
    ": The sample matches with the hypothesized distribution.\n",
    "\n",
    ": The sample does not match with the hypothesized distribution.\n",
    "\n",
    "To decide which hypothesis to choose, we'll set a significance level of 0.1.\n",
    "\n",
    "late_shipments, incoterm_counts, and hypothesized from the last exercise are available. chisquare from scipy.stats has been loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Using the incoterm_counts and hypothesized datasets, perform a chi-square goodness of fit test on the incoterm counts, n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a goodness of fit test on the incoterm counts n\n",
    "gof_test = chisquare(f_obs=incoterm_counts['n'], \n",
    "                     f_exp=hypothesized['n'])\n",
    "\n",
    "# Print gof_test results\n",
    "print(gof_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "What should you conclude from the hypothesis test?\n",
    "# Possible answers\n",
    "\n",
    "( ) Reject the null hypothesis and conclude that n follows the distribution specified by hypothesized.\n",
    "\n",
    "( ) Fail to reject the null hypothesis and conclude that n does not follow the distribution specified by hypothesized.\n",
    "\n",
    "( ) Reject the null hypothesis and conclude that n does not follow the distribution specified by hypothesized.\n",
    "\n",
    "(x) Fail to reject the null hypothesis and conclude that n follows the distribution specified by hypothesized."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
