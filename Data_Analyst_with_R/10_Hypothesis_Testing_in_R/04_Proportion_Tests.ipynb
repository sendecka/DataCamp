{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Non-Parametric Tests\n",
    "\n",
    "Learn about the assumptions made by parametric hypothesis tests and see how simulation-based and rank-based non-parametric tests can be used when those assumptions aren't met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common assumptions of hypothesis tests\n",
    "\n",
    "Hypothesis tests make assumptions about the dataset that they are testing, and the conclusions you draw from the test results are only valid if those assumptions hold. While some assumptions differ between types of test, others are common to all hypothesis tests.\n",
    "\n",
    "Which of the following statements is a common assumption of hypothesis tests?\n",
    "\n",
    "# Possible Answers\n",
    "\n",
    "(x) Sample observations are collected deterministically from the population.\n",
    "\n",
    "( ) Sample observations are correlated with each other.\n",
    "\n",
    "( ) Sample observations have no direct relationship with each other.\n",
    "\n",
    "( ) Sample sizes are greater than thirty observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sample size\n",
    "\n",
    "In order to conduct a hypothesis test, and be sure that the result is fair, a sample must meet three requirements: it is a random sample of the population; the observations are independent; and there are enough observations. Of these, only the last condition is easily testable with code.\n",
    "\n",
    "The minimum sample size depends on the type of hypothesis tests you want to perform. Let's test some scenarios on the late_shipments dataset.\n",
    "\n",
    "late_shipments is available; dplyr is loaded.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "- Using the late_shipments dataset, get counts by the freight_cost_group columns.\n",
    "- Insert a suitable number to inspect whether the counts are \"big enough\" for a two sample t-test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts by freight_cost_group\n",
    "counts <- late_shipments %>%\n",
    "  count(freight_cost_group)\n",
    "\n",
    "# See the result\n",
    "counts\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "all(counts$n >= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the late_shipments dataset, get counts by the late column.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for a one sample proportion test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts by late\n",
    "counts <- late_shipments %>%\n",
    "  count(late)\n",
    "\n",
    "# See the result\n",
    "counts\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "all(counts$n >= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the late_shipments dataset, get counts by the vendor_inco_term and freight_cost_group columns.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for a chi-square independence test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values of vendor_inco_term and freight_cost_group\n",
    "counts <- late_shipments %>%\n",
    "  count(vendor_inco_term, freight_cost_group)\n",
    "\n",
    "# See the result\n",
    "counts\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "all(counts$n >= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the late_shipments dataset, get counts by the shipment_mode column.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for an ANOVA test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values of shipment_mode\n",
    "counts <- late_shipments %>%\n",
    "  count(shipment_mode)\n",
    "\n",
    "# See the result\n",
    "counts\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "all(counts$n >= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is only one test\n",
    "\n",
    "You've encountered several types of traditional hypothesis test: t-tests, ANOVA tests, proportion tests, and chi-square tests. You may have noticed that there were similarities in the workflow for performing each test.\n",
    "\n",
    "Allen Downey proposed that all traditional hypothesis tests were special cases of a generic hypothesis test. He called this the \"There is Only One Test\" framework, and it forms a \"grammar of hypothesis tests\", analogous to the \"grammar of graphics\" implemented by ggplot2.\n",
    "\n",
    "In which situations will the \"There is Only One Test\" framework provide p-value and decision rule results that are different than a traditional method like prop_test()?\n",
    "\n",
    "# Possible Answers\n",
    "\n",
    "(x) The results should always be similar.\n",
    "\n",
    "( ) When the assumptions for the traditional method are not met.\n",
    "\n",
    "( ) When the sample size is large enough that the Central Limit Theorem applies.\n",
    "\n",
    "( ) When groups in the dataset are perfectly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying and hypothesizing\n",
    "\n",
    "In Chapter 3, you ran a two sample proportion test on the proportion of late shipments across freight cost groups. Recall the hypotheses.\n",
    "\n",
    "Let's compare that traditional approach using prop_test() with a simulation-based infer pipeline.\n",
    "\n",
    "late_shipments is available; dplyr and infer are loaded.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "Question\n",
    "Run the proportion test code (previously seen in Chapter 3). Assuming a significance level of alpha = 0.05, what does the evidence suggest?\n",
    "\n",
    "Possible answers\n",
    "\n",
    "(x) The p-value is less than or equal to the significance level, so you should reject the null hypothesis that the proportion of late shipments is the same for each freight cost group.\n",
    "\n",
    "( ) The p-value is less than or equal to the significance level, so you should fail to reject the null hypothesis that the proportion of late shipments is the same for each freight cost group.\n",
    "\n",
    "( ) The p-value is greater than the significance level, so you should reject the null hypothesis that the proportion of late shipments is the same for each freight cost group.\n",
    "\n",
    "( ) The p-value is greater than the significance level, so you should fail to reject the null hypothesis that the proportion of late shipments is the same for each freight cost group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM.result = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the late_shipments dataset, specify that we are interested in late proportions across freight_cost_group, where \"Yes\" denotes success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify that we are interested in late proportions across freight_cost_groups, where \"Yes\" denotes success\n",
    "specified <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  )\n",
    "\n",
    "# See the result\n",
    "specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extend the pipeline to declare a null hypothesis that the variables are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the pipeline to declare a null hypothesis that the variables are independent\n",
    "hypothesized <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\")\n",
    "\n",
    "# See the result\n",
    "hypothesized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating & calculating\n",
    "\n",
    "The infer pipeline for hypothesis testing requires four steps to calculate the null distribution: specify, hypothesize, generate, and calculate.\n",
    "\n",
    "Let's continue the pipeline you began in the previous coding exercise. We'll get a set of differences in proportions that are distributed as though the null hypothesis, that the proportion of late shipments is the same across freight cost groups, is true.\n",
    "\n",
    "late_shipments is available; dplyr, infer, and ggplot2 are loaded.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "- Extend the infer pipeline to generate two thousand permutation replicates. (Note this will take a few seconds to complete.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the pipeline to generate 2000 permutations\n",
    "generated <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\")\n",
    "\n",
    "# See the result\n",
    "generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the infer pipeline for the null distribution by calculating the difference in proportions, setting the order to expensive proportion minus reasonable proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the pipeline to calculate the difference in proportions (expensive minus reasonable)\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\") %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# See the result\n",
    "null_distn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the null distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\") %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# Visualize the null distribution\n",
    "visualize(null_distn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed statistic and p-value\n",
    "\n",
    "You now have a null distribution. In order to get a p-value and weigh up the evidence against the null hypothesis, you need to calculate the difference in proportions that is observed in the late_shipments sample.\n",
    "\n",
    "late_shipments is available; dplyr, infer, and ggplot2 are loaded.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "- Copy, paste, and modify the null distribution pipeline to get the observed statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distn <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\") %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# Copy, paste, and modify the pipeline to get the observed statistic\n",
    "obs_stat <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# See the result\n",
    "obs_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the null distribution, adding a vertical line at the observed statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\") %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "obs_stat <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# Visualize the null dist'n, adding a vertical line at the observed statistic\n",
    "visualize(null_distn) +\n",
    "  geom_vline(aes(xintercept = stat), data = obs_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the p-value from the null distribution and observed statistic, assuming an appropriate direction for the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 2000, type = \"permute\") %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "obs_stat <- late_shipments %>% \n",
    "  specify(\n",
    "    late ~ freight_cost_group, \n",
    "    success = \"Yes\"\n",
    "  ) %>% \n",
    "  calculate(\n",
    "    stat = \"diff in props\", \n",
    "    order = c(\"expensive\", \"reasonable\")\n",
    "  )\n",
    "\n",
    "# Get the p-value\n",
    "p_value <- get_p_value(\n",
    "  null_distn, obs_stat, \n",
    "  direction = \"greater\"\n",
    ")\n",
    "\n",
    "# See the result\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation-based t-test\n",
    "\n",
    "In Chapter 2 you manually performed the steps for a t-test to explore these hypotheses.\n",
    "\n",
    ": The mean weight of shipments that weren't late is the same as the mean weight of shipments that were late.\n",
    "\n",
    ": The mean weight of shipments that weren't late is less than the mean weight of shipments that were late.\n",
    "\n",
    "You can run the test more concisely using infer's t_test().\n",
    "\n",
    "late_shipments %>% \n",
    "  t_test(\n",
    "    weight_kilograms ~ late,\n",
    "    order = c(\"No\", \"Yes\"),\n",
    "    alternative = \"less\"\n",
    "  )\n",
    "t_test() assumes that the null distribution is normal. We can avoid assumptions by using a simulation-based non-parametric equivalent.\n",
    "\n",
    "late_shipments is available; dplyr and infer are loaded.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "- Specify weight in kilograms versus whether or not the shipment was late.\n",
    "- Declare a null hypothesis of independence.\n",
    "- Generate 1000 permutation replicates.\n",
    "- Calculate the difference in means, setting the order as \"No\" minus \"Yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out the null distribution pipeline\n",
    "null_distn <- late_shipments %>% \n",
    "  # Specify weight_kilograms vs. late\n",
    "  specify(weight_kilograms ~ late) %>% \n",
    "  # Declare a null hypothesis of independence\n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  # Generate 1000 permutation replicates\n",
    "  generate(reps = 1000, type = \"permute\") %>% \n",
    "  # Calculate the difference in means (\"No\" minus \"Yes\")\n",
    "  calculate(stat = \"diff in means\", order = c(\"No\", \"Yes\"))\n",
    "\n",
    "# See the results\n",
    "null_distn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the difference in means observed in the late_shipments dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(weight_kilograms ~ late) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 1000, type = \"permute\") %>% \n",
    "  calculate(stat = \"diff in means\", order = c(\"No\", \"Yes\"))\n",
    "\n",
    "# Calculate the observed difference in means\n",
    "obs_stat <- late_shipments %>% \n",
    "  specify(weight_kilograms ~ late) %>% \n",
    "  calculate(stat = \"diff in means\", order = c(\"No\", \"Yes\"))\n",
    "\n",
    "# See the result\n",
    "obs_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the p-value from the null distribution and the observed difference in means, setting an appropriate direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "null_distn <- late_shipments %>% \n",
    "  specify(weight_kilograms ~ late) %>% \n",
    "  hypothesize(null = \"independence\") %>% \n",
    "  generate(reps = 1000, type = \"permute\") %>% \n",
    "  calculate(stat = \"diff in means\", order = c(\"No\", \"Yes\"))\n",
    "obs_stat <- late_shipments %>% \n",
    "  specify(weight_kilograms ~ late) %>% \n",
    "  calculate(stat = \"diff in means\", order = c(\"No\", \"Yes\"))\n",
    "\n",
    "# Get the p-value\n",
    "p_value <- get_p_value(\n",
    "  null_distn, obs_stat,\n",
    "  direction = \"less\"\n",
    ")\n",
    "\n",
    "# See the result\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank sum tests\n",
    "\n",
    "Another class of non-parametric hypothesis tests are called rank sum tests. Ranks are the positions of numeric values from smallest to largest. Think of them as positions in running events: whoever has the fastest (smallest) time is rank 1, second fastest is rank 2, and so on.\n",
    "\n",
    "By calculating on the ranks of data instead of the actual values, you can avoid making assumptions about the distribution of the test statistic. It's most robust in the same way that a median is more robust than a mean.\n",
    "\n",
    "Two commonly used rank-based tests are the Wilcoxon-Mann-Whitney test, which is like a non-parametric t-test, and the Kruskal-Wallis test, which is like a non-parametric ANOVA.\n",
    "\n",
    "late_shipments is available.\n",
    "\n",
    "# Instructions:\n",
    "\n",
    "- Using the late_shipments dataset, run a Wilcoxon-Mann-Whitney test on the weight in kilograms versus whether or not the shipment was late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a Wilcoxon-Mann-Whitney test on weight_kilograms vs. late\n",
    "test_results <- wilcox.test(\n",
    "  weight_kilograms ~ late, \n",
    "  data = late_shipments\n",
    ")\n",
    "\n",
    "# See the result\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the late_shipments dataset, run a Kruskal-Wallace test on the weight in kilograms versus the shipment mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a Kruskal-Wallace test on weight_kilograms vs. shipment_mode\n",
    "test_results <- kruskal.test(\n",
    "  weight_kilograms ~ shipment_mode, \n",
    "  data = late_shipments\n",
    ")\n",
    "\n",
    "# See the result\n",
    "test_results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
